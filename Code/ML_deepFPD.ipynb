{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "dfdb67f5-6703-47ce-8ae4-c40d074e3918",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lime\n",
      "  Downloading lime-0.2.0.1.tar.gz (275 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.11/site-packages (from lime) (3.10.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/site-packages (from lime) (1.26.4)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.11/site-packages (from lime) (1.15.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/site-packages (from lime) (4.67.1)\n",
      "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.11/site-packages (from lime) (1.6.1)\n",
      "Requirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.11/site-packages (from lime) (0.25.2)\n",
      "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/site-packages (from scikit-image>=0.12->lime) (3.3)\n",
      "Requirement already satisfied: pillow>=10.1 in /usr/local/lib/python3.11/site-packages (from scikit-image>=0.12->lime) (10.4.0)\n",
      "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/site-packages (from scikit-image>=0.12->lime) (2.37.0)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/site-packages (from scikit-image>=0.12->lime) (2025.3.30)\n",
      "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/site-packages (from scikit-image>=0.12->lime) (24.1)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/site-packages (from scikit-image>=0.12->lime) (0.4)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/site-packages (from scikit-learn>=0.18->lime) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/site-packages (from scikit-learn>=0.18->lime) (3.6.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/site-packages (from matplotlib->lime) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/site-packages (from matplotlib->lime) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/site-packages (from matplotlib->lime) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/site-packages (from matplotlib->lime) (1.4.8)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/site-packages (from matplotlib->lime) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/site-packages (from matplotlib->lime) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib->lime) (1.16.0)\n",
      "Building wheels for collected packages: lime\n",
      "  Building wheel for lime (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for lime: filename=lime-0.2.0.1-py3-none-any.whl size=283913 sha256=07993a0c6ffb700bd489c2415218ad518da07a6bf510262c07eddc7e982ef3a3\n",
      "  Stored in directory: /root/.cache/pip/wheels/85/fa/a3/9c2d44c9f3cd77cf4e533b58900b2bf4487f2a17e8ec212a3d\n",
      "Successfully built lime\n",
      "Installing collected packages: lime\n",
      "Successfully installed lime-0.2.0.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# pip install treeinterpreter\n",
    "!pip install lime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a80af4e2-88de-45f1-b17e-9881a9a9ef39",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Object', 'console', 'window'}\n"
     ]
    }
   ],
   "source": [
    "#token Extraction\n",
    "\n",
    "# Sample JavaScript API keywords (this list can be expanded)\n",
    "JS_API_KEYWORDS = {\"document\", \"window\", \"console\", \"Array\", \"Object\", \"Function\", \"setTimeout\", \"clearInterval\"}\n",
    "\n",
    "def tokenize_js(js_code):\n",
    "    \"\"\"Tokenize JavaScript code using esprima.\"\"\"\n",
    "    tokens = esprima.tokenize(js_code)\n",
    "    return [token.value for token in tokens]\n",
    "\n",
    "def filter_tokens(js_codes, frequency_threshold=50):\n",
    "    \"\"\"Filter tokens based on frequency threshold and JS API keywords.\"\"\"\n",
    "    all_tokens = []\n",
    "    \n",
    "    # Tokenize all scripts\n",
    "    for code in js_codes:\n",
    "        all_tokens.extend(tokenize_js(code))\n",
    "    \n",
    "    # Compute token frequencies\n",
    "    token_counts = Counter(all_tokens)\n",
    "    \n",
    "    # Filter tokens\n",
    "    filtered_tokens = {token for token, count in token_counts.items() if count >= frequency_threshold or token in JS_API_KEYWORDS}\n",
    "    \n",
    "    return filtered_tokens\n",
    "\n",
    "# Example usage\n",
    "js_scripts = [\n",
    "    \"console.log('Hello, World!'); var x = 10; function test() { return x; }\",\n",
    "    \"window.alert('Test'); let y = 20; Object.keys({a:1, b:2});\"\n",
    "]\n",
    "\n",
    "filtered_tokens = filter_tokens(js_scripts)\n",
    "print(filtered_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "90458620-919e-406d-9d60-294b02afb728",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature vector: {'FunctionDeclaration:test': 1, 'VariableDeclarator:x': 1, 'VariableDeclarator:y': 1, 'MemberExpression:console': 3, 'MemberExpression:log': 3, 'BinaryExpression:x': 2, 'BinaryExpression:y': 2, 'UpdateExpression:y': 1}\n"
     ]
    }
   ],
   "source": [
    "#AST feature extraction\n",
    "\n",
    "class JSASTFeatureExtractor:\n",
    "    def __init__(self):\n",
    "        self.js_apis = {\n",
    "            'console', 'log', 'localStorage', 'setItem',\n",
    "            'test', 'x', 'y', 'key', 'value',  # Identifiers from your code\n",
    "            'document', 'window', 'Array', 'String'  # Common JS APIs\n",
    "        }\n",
    "    \n",
    "    def extract_features(self, js_code):\n",
    "        try:\n",
    "            ast = esprima.parseScript(js_code)\n",
    "            features = []\n",
    "            self._traverse_ast(ast, None, features)\n",
    "            return self._filter_features(features)\n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing JavaScript: {str(e)}\")\n",
    "            return []\n",
    "    \n",
    "    def _traverse_ast(self, node, parent, features):\n",
    "        # Process current node\n",
    "        if hasattr(node, 'type'):\n",
    "            node_type = node.type\n",
    "            # Capture identifiers and literals with their parent context\n",
    "            if node_type == 'Identifier':\n",
    "                if parent and hasattr(parent, 'type'):\n",
    "                    features.append(f\"{parent.type}:{node.name}\")\n",
    "            elif node_type == 'Literal':\n",
    "                if parent and hasattr(parent, 'type'):\n",
    "                    features.append(f\"{parent.type}:{node.value}\")\n",
    "            \n",
    "            # Recursively process child nodes\n",
    "            for child in self._get_child_nodes(node):\n",
    "                self._traverse_ast(child, node, features)\n",
    "    \n",
    "    def _get_child_nodes(self, node):\n",
    "        children = []\n",
    "        if not hasattr(node, '__dict__'):\n",
    "            return children\n",
    "            \n",
    "        # Handle different node structures\n",
    "        for attr, value in vars(node).items():\n",
    "            if attr.startswith('_') or attr in ['type', 'loc', 'range']:\n",
    "                continue\n",
    "                \n",
    "            if isinstance(value, list):\n",
    "                children.extend([item for item in value if hasattr(item, 'type')])\n",
    "            elif hasattr(value, 'type'):\n",
    "                children.append(value)\n",
    "        \n",
    "        return children\n",
    "    \n",
    "    def _filter_features(self, features):\n",
    "        return [f for f in features if any(api in f.split(':')[1] for api in self.js_apis)]\n",
    "    \n",
    "    def get_feature_vector(self, js_code):\n",
    "        features = self.extract_features(js_code)\n",
    "        feature_counts = defaultdict(int)\n",
    "        for feature in features:\n",
    "            feature_counts[feature] += 1\n",
    "        return dict(feature_counts)\n",
    "\n",
    "# Test with your code\n",
    "extractor = JSASTFeatureExtractor()\n",
    "js_code = \"\"\"\n",
    "    function test() {\n",
    "        var x = 10;\n",
    "        var y = 20;\n",
    "        console.log(x + y);\n",
    "        if (x > 5) {\n",
    "            console.log('X is greater than 5');\n",
    "        } else {\n",
    "            console.log('X is not greater than 5');\n",
    "        }\n",
    "        while (y > 0) {\n",
    "            y--;\n",
    "        }\n",
    "    }\n",
    "    \"\"\"\n",
    "\n",
    "# print(\"All features (unfiltered):\")\n",
    "ast = esprima.parseScript(js_code)\n",
    "features = []\n",
    "extractor._traverse_ast(ast, None, features)\n",
    "# for f in features:\n",
    "#     print(f)\n",
    "\n",
    "# print(\"\\nFiltered features:\")\n",
    "filtered = extractor._filter_features(features)\n",
    "# for f in filtered:\n",
    "#     print(f)\n",
    "\n",
    "print(\"\\nFeature vector:\", extractor.get_feature_vector(js_code))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "207ee946-0356-4c2b-bc3d-ad3ed1f727a7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "[]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00         1\n",
      "   macro avg       1.00      1.00      1.00         1\n",
      "weighted avg       1.00      1.00      1.00         1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import esprima\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "# Define the AST feature extractor\n",
    "class JSASTFeatureExtractor:\n",
    "    def __init__(self):\n",
    "        self.js_apis = {\n",
    "            'console', 'log', 'localStorage', 'setItem',\n",
    "            'document', 'window', 'Array', 'String'\n",
    "        }\n",
    "\n",
    "    def extract_features(self, js_code):\n",
    "        \"\"\"Extract features from the provided JavaScript code.\"\"\"\n",
    "        try:\n",
    "            ast = esprima.parseScript(js_code)\n",
    "            features = []\n",
    "            self._traverse_ast(ast.body, features)\n",
    "            return self._filter_features(features)\n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing JavaScript: {str(e)}\")\n",
    "            return []\n",
    "\n",
    "    def _traverse_ast(self, nodes, features):\n",
    "        \"\"\"Traverse the AST to create features based on statements.\"\"\"\n",
    "        for node in nodes:\n",
    "            if hasattr(node, 'type'):\n",
    "                node_type = node.type\n",
    "                if node_type in ['Identifier', 'Literal']:\n",
    "                    statement = self._get_statement(node)\n",
    "                    features.append(statement)\n",
    "                # Additional handling for control flow constructs\n",
    "                if node_type == 'IfStatement':\n",
    "                    features.append(f\"If: {self._get_statement(node.test)}\")\n",
    "                    self._traverse_ast([node.consequent], features)\n",
    "                    if node.alternate:\n",
    "                        self._traverse_ast([node.alternate], features)\n",
    "\n",
    "    def _get_statement(self, node):\n",
    "        \"\"\"Get a string representation of a statement for the features.\"\"\"\n",
    "        if node.type == 'Identifier':\n",
    "            return f\"Identifier: {node.name}\"\n",
    "        elif node.type == 'Literal':\n",
    "            return f\"Literal: {node.value}\"\n",
    "        return \"Unknown Statement\"\n",
    "\n",
    "    def _filter_features(self, features):\n",
    "        \"\"\"Filter features to include only those matching JavaScript APIs.\"\"\"\n",
    "        return [f for f in features if any(api in f for api in self.js_apis)]\n",
    "\n",
    "# Token feature extraction function\n",
    "def extract_token_features(js_code):\n",
    "    \"\"\"Tokenize JavaScript code and filter tokens based on frequency.\"\"\"\n",
    "    tokens = esprima.tokenize(js_code)\n",
    "    token_counts = Counter(token.value for token in tokens)\n",
    "\n",
    "    # Filter tokens based on frequency (keeping top 20%)\n",
    "    frequency_threshold = 0.2 * len(token_counts)  # Change this if needed\n",
    "    filtered_tokens = {token for token, count in token_counts.items() if count >= frequency_threshold}\n",
    "\n",
    "    return filtered_tokens\n",
    "\n",
    "# Function to extract combined features\n",
    "def extract_combined_features(js_code):\n",
    "    \"\"\"Extract combined features from both AST and token features.\"\"\"\n",
    "    ast_extractor = JSASTFeatureExtractor()\n",
    "    ast_features = ast_extractor.extract_features(js_code)\n",
    "    print(ast_features)\n",
    "    \n",
    "    # Extract token features\n",
    "    token_features = extract_token_features(js_code)\n",
    "\n",
    "    # Combine features (here we use counts)\n",
    "    combined_features = Counter(ast_features + list(token_features))\n",
    "    \n",
    "    # Convert combined features to a fixed-size vector\n",
    "    feature_vector = np.zeros(256)  # Define a fixed size for the feature vector\n",
    "    for i, feature in enumerate(combined_features):\n",
    "        if i < 256:  # Limit to 256 dimensions\n",
    "            feature_vector[i] = combined_features[feature]\n",
    "    \n",
    "    return feature_vector\n",
    "\n",
    "# Sample JavaScript code snippets (replace with your dataset)\n",
    "js_code_samples = [\n",
    "    \"console.log('Hello, World!'); var x = 10;\",\n",
    "    \"window.alert('Test'); let y = 20; Object.keys({a:1, b:2});\",\n",
    "    \"var a = b + c; if (a > 10) { console.log(a); }\"\n",
    "]\n",
    "\n",
    "# Assume we have the following labels for the above snippets\n",
    "labels = [0, 1, 0]  # 0 = benign, 1 = malicious (example labels)\n",
    "\n",
    "# Prepare feature vectors\n",
    "feature_vectors = []\n",
    "for code in js_code_samples:\n",
    "    feature_vector = extract_combined_features(code)\n",
    "    feature_vectors.append(feature_vector)\n",
    "\n",
    "# Convert to NumPy array for machine learning\n",
    "X = np.array(feature_vectors)\n",
    "\n",
    "# Step 3: Prepare the Dataset\n",
    "y = np.array(labels)  # Labels for the training\n",
    "\n",
    "# Step 4: Model Training\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Step 5: Model Evaluation\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "15a6a507-ddb9-481b-a89a-4dd8217cfc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "# ML model with deppfpd features\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "import pandas as pd\n",
    "\n",
    "import joblib\n",
    "import json\n",
    "\n",
    "# import shap\n",
    "from lime.lime_text import LimeTextExplainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e112458c-221b-401d-afab-68d461290424",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('DeepFPD/DeepFPD/exp_n/fusion/train_data_styx/ast.npy','rb') as f:\n",
    "    ast_data=np.load(f,allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "384ec172-57e3-4f1e-82ba-98f47f62365f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('DeepFPD-Code/train/process_ast2/ast.npy','rb') as f:\n",
    "    ast_with_wasm=np.load(f,allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa1c9f77-481c-40e2-a578-39209415317b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 20 Important AST tuples (BoW features):\n",
      "MemberExpression:screen: 0.0214\n",
      "MemberExpression:fillText: 0.0192\n",
      "CallExpression:canvas: 0.0186\n",
      "MemberExpression:language: 0.0145\n",
      "MemberExpression:localStorage: 0.0118\n",
      "MemberExpression:appName: 0.0116\n",
      "MemberExpression:platform: 0.0110\n",
      "MemberExpression:fillStyle: 0.0106\n",
      "MemberExpression:colorDepth: 0.0105\n",
      "MemberExpression:fillRect: 0.0089\n",
      "MemberExpression:openDatabase: 0.0086\n",
      "MemberExpression:getContext: 0.0084\n",
      "MemberExpression:plugins: 0.0083\n",
      "MemberExpression:getTimezoneOffset: 0.0079\n",
      "MemberExpression:textBaseline: 0.0076\n",
      "MemberExpression:charCodeAt: 0.0074\n",
      "MemberExpression:font: 0.0071\n",
      "MemberExpression:cpuClass: 0.0068\n",
      "MemberExpression:getItem: 0.0068\n",
      "MemberExpression:attachShader: 0.0066\n"
     ]
    }
   ],
   "source": [
    "#feature importance\n",
    "\n",
    "# Load test AST sequences and true labels from the same file\n",
    "test_data = ast_data\n",
    "\n",
    "# Separate sequences and labels\n",
    "test_labels = []\n",
    "test_sequences = []\n",
    "\n",
    "for entry in test_data:\n",
    "    label, seq = entry\n",
    "    test_labels.append(label)\n",
    "    test_sequences.append(' '.join(map(str, seq)))\n",
    "\n",
    "# Load the saved vectorizer and model\n",
    "vectorizer = CountVectorizer(max_features=5000)\n",
    "X = vectorizer.fit_transform(test_sequences).toarray()\n",
    "labels = np.array(test_labels)\n",
    "\n",
    "# 10-Fold Stratified Cross-Validation\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Train final model on all data for feature importance analysis\n",
    "clf_bow = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf_bow.fit(X, labels)\n",
    "importances = clf_bow.feature_importances_\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "sorted_idx = np.argsort(importances)[::-1]\n",
    "\n",
    "# Load your original vocab (token -> index)\n",
    "with open('DeepFPD/DeepFPD/exp_n/fusion/train_data_styx/vocab.json', 'r') as f:\n",
    "    vocab = json.load(f)\n",
    "\n",
    "# Reverse it to get index -> token\n",
    "index_to_token = {v: k for k, v in vocab.items()}\n",
    "\n",
    "print(\"\\nTop 20 Important AST tuples (BoW features):\")\n",
    "# for idx in sorted_idx[:20]:\n",
    "#     print(f\"{feature_names[idx]}: {importances[idx]:.4f}\")\n",
    "\n",
    "for idx in sorted_idx[:20]:\n",
    "    token = feature_names[idx]\n",
    "    if token.isdigit():\n",
    "        token_int = int(token)\n",
    "        readable = index_to_token.get(token_int + 1, f\"[Unknown token {token_int}]\")  # +1 to account for 1-based vocab\n",
    "    else:\n",
    "        readable = token\n",
    "    print(f\"{readable}: {importances[idx]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "acfe0601-379b-4ed7-9f5b-f5a87516e30c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #shap\n",
    "# # import shap\n",
    "# # Load test AST sequences and true labels from the same file\n",
    "# test_data = ast_data\n",
    "\n",
    "# # Separate sequences and labels\n",
    "# test_labels = []\n",
    "# test_sequences = []\n",
    "\n",
    "# for entry in test_data:\n",
    "#     label, seq = entry\n",
    "#     test_labels.append(label)\n",
    "#     test_sequences.append(' '.join(map(str, seq)))\n",
    "\n",
    "# # Load the saved vectorizer and model\n",
    "# vectorizer = CountVectorizer(max_features=5000)\n",
    "# X = vectorizer.fit_transform(test_sequences).toarray()\n",
    "# labels = np.array(test_labels)\n",
    "\n",
    "# # 10-Fold Stratified Cross-Validation\n",
    "# skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# # Train final model on all data for feature importance and SHAP analysis\n",
    "# print('Starting Training')\n",
    "# clf_bow = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "# print('debug print')\n",
    "# clf_bow.fit(X, labels)\n",
    "# # importances = clf_bow.feature_importances_\n",
    "# # feature_names = vectorizer.get_feature_names_out()\n",
    "# # sorted_idx = np.argsort(importances)[::-1]\n",
    "\n",
    "# # print(\"\\nTop 20 Important AST tuples (BoW features):\")\n",
    "# # for idx in sorted_idx[:20]:\n",
    "# #     print(f\"{feature_names[idx]}: {importances[idx]:.4f}\")\n",
    "\n",
    "# # SHAP Analysis\n",
    "# print(\"\\nGenerating SHAP summary plot...\")\n",
    "# explainer = shap.TreeExplainer(clf_bow)\n",
    "# shap_values = explainer.shap_values(X)\n",
    "\n",
    "# # Plot summary for class 1 (fingerprinting class)\n",
    "# shap.summary_plot(shap_values[1], X, feature_names=feature_names, show=False)\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(\"shap_summary_class1.png\")\n",
    "# print(\"SHAP summary plot saved as 'shap_summary_class1.png'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "42a35491-f3b1-4783-be00-0e1e8b8209f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       546\n",
      "           1       0.99      0.87      0.92        76\n",
      "\n",
      "    accuracy                           0.98       622\n",
      "   macro avg       0.98      0.93      0.96       622\n",
      "weighted avg       0.98      0.98      0.98       622\n",
      "\n",
      "Fold 1 Accuracy: 0.9823\n",
      "\n",
      "Fold 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       546\n",
      "           1       1.00      0.88      0.94        76\n",
      "\n",
      "    accuracy                           0.99       622\n",
      "   macro avg       0.99      0.94      0.96       622\n",
      "weighted avg       0.99      0.99      0.99       622\n",
      "\n",
      "Fold 2 Accuracy: 0.9855\n",
      "\n",
      "Fold 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99       546\n",
      "           1       0.98      0.82      0.89        76\n",
      "\n",
      "    accuracy                           0.98       622\n",
      "   macro avg       0.98      0.91      0.94       622\n",
      "weighted avg       0.98      0.98      0.97       622\n",
      "\n",
      "Fold 3 Accuracy: 0.9759\n",
      "\n",
      "Fold 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       546\n",
      "           1       1.00      0.86      0.92        76\n",
      "\n",
      "    accuracy                           0.98       622\n",
      "   macro avg       0.99      0.93      0.96       622\n",
      "weighted avg       0.98      0.98      0.98       622\n",
      "\n",
      "Fold 4 Accuracy: 0.9823\n",
      "\n",
      "Fold 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       546\n",
      "           1       0.98      0.83      0.90        76\n",
      "\n",
      "    accuracy                           0.98       622\n",
      "   macro avg       0.98      0.91      0.94       622\n",
      "weighted avg       0.98      0.98      0.98       622\n",
      "\n",
      "Fold 5 Accuracy: 0.9775\n",
      "\n",
      "Fold 6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       546\n",
      "           1       0.99      0.88      0.93        76\n",
      "\n",
      "    accuracy                           0.98       622\n",
      "   macro avg       0.98      0.94      0.96       622\n",
      "weighted avg       0.98      0.98      0.98       622\n",
      "\n",
      "Fold 6 Accuracy: 0.9839\n",
      "\n",
      "Fold 7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       546\n",
      "           1       0.96      0.95      0.95        76\n",
      "\n",
      "    accuracy                           0.99       622\n",
      "   macro avg       0.98      0.97      0.97       622\n",
      "weighted avg       0.99      0.99      0.99       622\n",
      "\n",
      "Fold 7 Accuracy: 0.9887\n",
      "\n",
      "Fold 8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98       546\n",
      "           1       0.98      0.73      0.84        75\n",
      "\n",
      "    accuracy                           0.97       621\n",
      "   macro avg       0.97      0.87      0.91       621\n",
      "weighted avg       0.97      0.97      0.96       621\n",
      "\n",
      "Fold 8 Accuracy: 0.9662\n",
      "\n",
      "Fold 9\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       545\n",
      "           1       0.95      0.76      0.85        76\n",
      "\n",
      "    accuracy                           0.97       621\n",
      "   macro avg       0.96      0.88      0.91       621\n",
      "weighted avg       0.97      0.97      0.96       621\n",
      "\n",
      "Fold 9 Accuracy: 0.9662\n",
      "\n",
      "Fold 10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       545\n",
      "           1       0.97      0.84      0.90        76\n",
      "\n",
      "    accuracy                           0.98       621\n",
      "   macro avg       0.97      0.92      0.94       621\n",
      "weighted avg       0.98      0.98      0.98       621\n",
      "\n",
      "Fold 10 Accuracy: 0.9775\n",
      "\n",
      "Average Accuracy across 10 folds: 0.9786 ± 0.0072\n",
      "Average Precision across 10 folds: 0.9802\n",
      "Average Recall across 10 folds: 0.8418\n"
     ]
    }
   ],
   "source": [
    "#bow based\n",
    "\n",
    "# Prepare labels and AST sequences\n",
    "labels = []\n",
    "ast_sequences = []\n",
    "\n",
    "for entry in ast_data:\n",
    "    label, seq = entry\n",
    "    labels.append(label)\n",
    "    ast_sequences.append(' '.join(map(str, seq)))  # convert numeric tokens to strings\n",
    "\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Choose vectorization method (Bag-of-Words or TF-IDF)\n",
    "vectorizer = CountVectorizer(max_features=5000)  # Use TfidfVectorizer for TF-IDF\n",
    "X = vectorizer.fit_transform(ast_sequences).toarray()\n",
    "\n",
    "# 10-Fold Stratified Cross-Validation\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "accuracies = []\n",
    "precisions = [] \n",
    "recalls = []\n",
    "fold = 1\n",
    "\n",
    "for train_index, test_index in skf.split(X, labels):\n",
    "    print(f\"\\nFold {fold}\")\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = labels[train_index], labels[test_index]\n",
    "\n",
    "    clf_bow = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    clf_bow.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf_bow.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "    precision, recall, _, _ = precision_recall_fscore_support(y_test, y_pred, average='binary')\n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)\n",
    "\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(f\"Fold {fold} Accuracy: {accuracy:.4f}\")\n",
    "    fold += 1\n",
    "\n",
    "print(f\"\\nAverage Accuracy across 10 folds: {np.mean(accuracies):.4f} ± {np.std(accuracies):.4f}\")\n",
    "print(f\"Average Precision across 10 folds: {np.mean(precisions):.4f}\")\n",
    "print(f\"Average Recall across 10 folds: {np.mean(recalls):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "2f32a90a-c634-466c-b8a6-eb166254a410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98       941\n",
      "           1       0.98      0.73      0.84       157\n",
      "\n",
      "    accuracy                           0.96      1098\n",
      "   macro avg       0.97      0.87      0.91      1098\n",
      "weighted avg       0.96      0.96      0.96      1098\n",
      "\n",
      "Fold 1 Accuracy: 0.9599\n",
      "\n",
      "Fold 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97       941\n",
      "           1       0.98      0.70      0.82       157\n",
      "\n",
      "    accuracy                           0.96      1098\n",
      "   macro avg       0.97      0.85      0.90      1098\n",
      "weighted avg       0.96      0.96      0.95      1098\n",
      "\n",
      "Fold 2 Accuracy: 0.9554\n",
      "\n",
      "Fold 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98       941\n",
      "           1       0.97      0.73      0.83       157\n",
      "\n",
      "    accuracy                           0.96      1098\n",
      "   macro avg       0.96      0.86      0.90      1098\n",
      "weighted avg       0.96      0.96      0.95      1098\n",
      "\n",
      "Fold 3 Accuracy: 0.9572\n",
      "\n",
      "Fold 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98       940\n",
      "           1       1.00      0.75      0.86       158\n",
      "\n",
      "    accuracy                           0.96      1098\n",
      "   macro avg       0.98      0.87      0.92      1098\n",
      "weighted avg       0.97      0.96      0.96      1098\n",
      "\n",
      "Fold 4 Accuracy: 0.9636\n",
      "\n",
      "Fold 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97       940\n",
      "           1       0.98      0.68      0.81       158\n",
      "\n",
      "    accuracy                           0.95      1098\n",
      "   macro avg       0.97      0.84      0.89      1098\n",
      "weighted avg       0.95      0.95      0.95      1098\n",
      "\n",
      "Fold 5 Accuracy: 0.9526\n",
      "\n",
      "Fold 6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97       940\n",
      "           1       0.98      0.69      0.81       158\n",
      "\n",
      "    accuracy                           0.95      1098\n",
      "   macro avg       0.97      0.84      0.89      1098\n",
      "weighted avg       0.95      0.95      0.95      1098\n",
      "\n",
      "Fold 6 Accuracy: 0.9536\n",
      "\n",
      "Fold 7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98       940\n",
      "           1       0.97      0.72      0.82       158\n",
      "\n",
      "    accuracy                           0.96      1098\n",
      "   macro avg       0.96      0.86      0.90      1098\n",
      "weighted avg       0.96      0.96      0.95      1098\n",
      "\n",
      "Fold 7 Accuracy: 0.9563\n",
      "\n",
      "Fold 8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98       940\n",
      "           1       0.99      0.75      0.85       158\n",
      "\n",
      "    accuracy                           0.96      1098\n",
      "   macro avg       0.98      0.87      0.92      1098\n",
      "weighted avg       0.96      0.96      0.96      1098\n",
      "\n",
      "Fold 8 Accuracy: 0.9627\n",
      "\n",
      "Fold 9\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97       940\n",
      "           1       0.96      0.64      0.77       157\n",
      "\n",
      "    accuracy                           0.95      1097\n",
      "   macro avg       0.95      0.82      0.87      1097\n",
      "weighted avg       0.95      0.95      0.94      1097\n",
      "\n",
      "Fold 9 Accuracy: 0.9453\n",
      "\n",
      "Fold 10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98       940\n",
      "           1       0.97      0.73      0.83       157\n",
      "\n",
      "    accuracy                           0.96      1097\n",
      "   macro avg       0.96      0.86      0.90      1097\n",
      "weighted avg       0.96      0.96      0.95      1097\n",
      "\n",
      "Fold 10 Accuracy: 0.9572\n",
      "\n",
      "Average Accuracy across 10 folds: 0.9564 ± 0.0050\n",
      "Average Precision across 10 folds: 0.9789\n",
      "Average Recall across 10 folds: 0.7111\n"
     ]
    }
   ],
   "source": [
    "#bow based (ast with wasm)\n",
    "\n",
    "# Prepare labels and AST sequences\n",
    "labels_wasm = []\n",
    "ast_sequences_wasm = []\n",
    "\n",
    "for entry in ast_with_wasm:\n",
    "    label, seq = entry\n",
    "    labels_wasm.append(label)\n",
    "    ast_sequences_wasm.append(' '.join(map(str, seq)))  # convert numeric tokens to strings\n",
    "\n",
    "labels_wasm = np.array(labels_wasm)\n",
    "\n",
    "# Choose vectorization method (Bag-of-Words or TF-IDF)\n",
    "vectorizer_wasm = CountVectorizer(max_features=5000)  # Use TfidfVectorizer for TF-IDF\n",
    "X = vectorizer_wasm.fit_transform(ast_sequences_wasm).toarray()\n",
    "\n",
    "# 10-Fold Stratified Cross-Validation\n",
    "skf_wasm = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "accuracies = []\n",
    "precisions = [] \n",
    "recalls = []\n",
    "fold = 1\n",
    "\n",
    "for train_index, test_index in skf_wasm.split(X, labels_wasm):\n",
    "    print(f\"\\nFold {fold}\")\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = labels_wasm[train_index], labels_wasm[test_index]\n",
    "\n",
    "    clf_bow_wasm = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    clf_bow_wasm.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf_bow_wasm.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "    precision, recall, _, _ = precision_recall_fscore_support(y_test, y_pred, average='binary')\n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)\n",
    "\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(f\"Fold {fold} Accuracy: {accuracy:.4f}\")\n",
    "    fold += 1\n",
    "\n",
    "print(f\"\\nAverage Accuracy across 10 folds: {np.mean(accuracies):.4f} ± {np.std(accuracies):.4f}\")\n",
    "print(f\"Average Precision across 10 folds: {np.mean(precisions):.4f}\")\n",
    "print(f\"Average Recall across 10 folds: {np.mean(recalls):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "6198b390-08f8-4f2d-a595-ee55f90fea6d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97       546\n",
      "           1       0.98      0.64      0.78        76\n",
      "\n",
      "    accuracy                           0.95       622\n",
      "   macro avg       0.97      0.82      0.88       622\n",
      "weighted avg       0.96      0.95      0.95       622\n",
      "\n",
      "Fold 1 Accuracy: 0.9550\n",
      "\n",
      "Fold 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98       546\n",
      "           1       0.98      0.67      0.80        76\n",
      "\n",
      "    accuracy                           0.96       622\n",
      "   macro avg       0.97      0.83      0.89       622\n",
      "weighted avg       0.96      0.96      0.95       622\n",
      "\n",
      "Fold 2 Accuracy: 0.9582\n",
      "\n",
      "Fold 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97       546\n",
      "           1       0.98      0.62      0.76        76\n",
      "\n",
      "    accuracy                           0.95       622\n",
      "   macro avg       0.96      0.81      0.87       622\n",
      "weighted avg       0.95      0.95      0.95       622\n",
      "\n",
      "Fold 3 Accuracy: 0.9518\n",
      "\n",
      "Fold 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98       546\n",
      "           1       1.00      0.67      0.80        76\n",
      "\n",
      "    accuracy                           0.96       622\n",
      "   macro avg       0.98      0.84      0.89       622\n",
      "weighted avg       0.96      0.96      0.96       622\n",
      "\n",
      "Fold 4 Accuracy: 0.9598\n",
      "\n",
      "Fold 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97       546\n",
      "           1       1.00      0.63      0.77        76\n",
      "\n",
      "    accuracy                           0.95       622\n",
      "   macro avg       0.98      0.82      0.87       622\n",
      "weighted avg       0.96      0.95      0.95       622\n",
      "\n",
      "Fold 5 Accuracy: 0.9550\n",
      "\n",
      "Fold 6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98       546\n",
      "           1       0.98      0.76      0.86        76\n",
      "\n",
      "    accuracy                           0.97       622\n",
      "   macro avg       0.98      0.88      0.92       622\n",
      "weighted avg       0.97      0.97      0.97       622\n",
      "\n",
      "Fold 6 Accuracy: 0.9695\n",
      "\n",
      "Fold 7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       546\n",
      "           1       1.00      0.84      0.91        76\n",
      "\n",
      "    accuracy                           0.98       622\n",
      "   macro avg       0.99      0.92      0.95       622\n",
      "weighted avg       0.98      0.98      0.98       622\n",
      "\n",
      "Fold 7 Accuracy: 0.9807\n",
      "\n",
      "Fold 8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97       546\n",
      "           1       0.98      0.59      0.73        75\n",
      "\n",
      "    accuracy                           0.95       621\n",
      "   macro avg       0.96      0.79      0.85       621\n",
      "weighted avg       0.95      0.95      0.94       621\n",
      "\n",
      "Fold 8 Accuracy: 0.9485\n",
      "\n",
      "Fold 9\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97       545\n",
      "           1       0.96      0.63      0.76        76\n",
      "\n",
      "    accuracy                           0.95       621\n",
      "   macro avg       0.96      0.81      0.87       621\n",
      "weighted avg       0.95      0.95      0.95       621\n",
      "\n",
      "Fold 9 Accuracy: 0.9517\n",
      "\n",
      "Fold 10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97       545\n",
      "           1       0.96      0.66      0.78        76\n",
      "\n",
      "    accuracy                           0.95       621\n",
      "   macro avg       0.96      0.83      0.88       621\n",
      "weighted avg       0.96      0.95      0.95       621\n",
      "\n",
      "Fold 10 Accuracy: 0.9549\n",
      "\n",
      "Average Accuracy across 10 folds: 0.9585 ± 0.0092\n",
      "Average Precision across 10 folds: 0.9822\n",
      "Average Recall across 10 folds: 0.6718\n"
     ]
    }
   ],
   "source": [
    "#embedding based feature prep\n",
    "\n",
    "# Prepare labels and AST sequences\n",
    "labels = []\n",
    "ast_sequences = []\n",
    "\n",
    "for entry in ast_data:\n",
    "    label, seq = entry\n",
    "    labels.append(label)\n",
    "    ast_sequences.append(seq)\n",
    "\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Define embedding dimensions\n",
    "vocab_size = max(max(seq) for seq in ast_sequences) + 1\n",
    "embed_dim = 64\n",
    "\n",
    "# Randomly initialized embeddings (you can replace this with trained embeddings)\n",
    "embedding_matrix = np.random.rand(vocab_size, embed_dim)\n",
    "\n",
    "# Function to compute average embeddings for sequences\n",
    "def average_embedding(seq, embedding_matrix):\n",
    "    embeddings = embedding_matrix[seq]\n",
    "    return np.mean(embeddings, axis=0)\n",
    "\n",
    "# Compute average embeddings for all sequences\n",
    "X = np.array([average_embedding(seq, embedding_matrix) for seq in ast_sequences])\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# 10-Fold Stratified Cross-Validation\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "accuracies = []\n",
    "recalls = []\n",
    "precisions = []\n",
    "fold = 1\n",
    "\n",
    "for train_index, test_index in skf.split(X, labels):\n",
    "    print(f\"\\nFold {fold}\")\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = labels[train_index], labels[test_index]\n",
    "\n",
    "    clf_em = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    clf_em.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf_em.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "    precision, recall, _, _ = precision_recall_fscore_support(y_test, y_pred, average='binary')\n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)\n",
    "\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(f\"Fold {fold} Accuracy: {accuracy:.4f}\")\n",
    "    fold += 1\n",
    "\n",
    "print(f\"\\nAverage Accuracy across 10 folds: {np.mean(accuracies):.4f} ± {np.std(accuracies):.4f}\")\n",
    "print(f\"Average Precision across 10 folds: {np.mean(precisions):.4f}\")\n",
    "print(f\"Average Recall across 10 folds: {np.mean(recalls):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "32224f5c-cef4-47e1-be81-1bec397a18bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scaler.joblib']"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save models and necessary data\n",
    "joblib.dump(clf_bow, 'rf_bow_model.joblib')\n",
    "joblib.dump(vectorizer, 'bow_vectorizer.joblib')\n",
    "\n",
    "joblib.dump(clf_em, 'rf__em_model.joblib')\n",
    "np.save('embedding_matrix.npy', embedding_matrix)\n",
    "joblib.dump(scaler, 'scaler.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "2fd724a1-2705-4990-9989-6771c0cdf551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data\n",
    "with open('DeepFPD-Code/test/process_ast2/ast.npy','rb') as f:\n",
    "    test_data_ = np.load(f,allow_pickle=True)\n",
    "with open('DeepFPD-Code/wasm_test/process_ast2/ast.npy','rb') as f:\n",
    "    wasm_test_data_ = np.load(f,allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "c2971846-86c3-4441-b34a-4d57042ec00e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 97.81%\n",
      "Precision: 86.67%\n",
      "Recall: 72.22%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate sequences and labels\n",
    "test_labels = []\n",
    "test_sequences = []\n",
    "\n",
    "for entry in test_data_:\n",
    "    label, seq = entry\n",
    "    test_labels.append(label)\n",
    "    test_sequences.append(' '.join(map(str, seq)))\n",
    "\n",
    "# vectorizer = joblib.load('bow_vectorizer.joblib')\n",
    "# Transform test sequences into BoW vectors\n",
    "X_test_bow = vectorizer.transform(test_sequences).toarray()\n",
    "\n",
    "# # Load your trained model\n",
    "# clf_bow = joblib.load('rf_bow_model.joblib')\n",
    "\n",
    "# Make predictions on test data\n",
    "predictions = clf_bow.predict(X_test_bow)\n",
    "\n",
    "# View predictions\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(test_labels, predictions)\n",
    "precision = precision_score(test_labels, predictions, average='binary')\n",
    "recall = recall_score(test_labels, predictions, average='binary')\n",
    "\n",
    "# print(predictions)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"Precision: {precision * 100:.2f}%\")\n",
    "print(f\"Recall: {recall * 100:.2f}%\")\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "71388e54-651e-45a4-b9b7-2d5744175788",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 96.55%\n",
      "Precision: 88.89%\n",
      "Recall: 44.44%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test data prep for bow model\n",
    "\n",
    "# Separate sequences and labels\n",
    "test_labels = []\n",
    "test_sequences = []\n",
    "\n",
    "# for entry in test_data_:\n",
    "for entry in wasm_test_data_:\n",
    "    label, seq = entry\n",
    "    test_labels.append(label)\n",
    "    test_sequences.append(' '.join(map(str, seq)))\n",
    "\n",
    "# vectorizer = joblib.load('bow_vectorizer.joblib')\n",
    "# Transform test sequences into BoW vectors\n",
    "X_test_bow = vectorizer.transform(test_sequences).toarray()\n",
    "\n",
    "# # Load your trained model\n",
    "# clf_bow = joblib.load('rf_bow_model.joblib')\n",
    "\n",
    "# Make predictions on test data\n",
    "predictions = clf_bow.predict(X_test_bow)\n",
    "\n",
    "# View predictions\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(test_labels, predictions)\n",
    "precision = precision_score(test_labels, predictions, average='binary')\n",
    "recall = recall_score(test_labels, predictions, average='binary')\n",
    "\n",
    "# print(predictions)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"Precision: {precision * 100:.2f}%\")\n",
    "print(f\"Recall: {recall * 100:.2f}%\")\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "acbc7847-391b-4cb6-bc0f-969b5811c33d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 83.07%\n",
      "Precision: 2.63%\n",
      "Recall: 5.56%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1,\n",
       "       1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1])"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate sequences and labels\n",
    "test_labels = []\n",
    "test_sequences = []\n",
    "\n",
    "for entry in test_data_:\n",
    "    label, seq = entry\n",
    "    test_labels.append(label)\n",
    "    test_sequences.append(' '.join(map(str, seq)))\n",
    "\n",
    "# vectorizer = joblib.load('bow_vectorizer.joblib')\n",
    "# Transform test sequences into BoW vectors\n",
    "X_test_bow = vectorizer.transform(test_sequences).toarray()\n",
    "\n",
    "# # Load your trained model\n",
    "# clf_bow = joblib.load('rf_bow_model.joblib')\n",
    "\n",
    "# Make predictions on test data\n",
    "predictions = clf_bow_wasm.predict(X_test_bow)\n",
    "\n",
    "# View predictions\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(test_labels, predictions)\n",
    "precision = precision_score(test_labels, predictions, average='binary')\n",
    "recall = recall_score(test_labels, predictions, average='binary')\n",
    "\n",
    "# print(predictions)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"Precision: {precision * 100:.2f}%\")\n",
    "print(f\"Recall: {recall * 100:.2f}%\")\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "30507691-b22e-490f-b211-2a59d70d7310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 83.39%\n",
      "Precision: 2.70%\n",
      "Recall: 5.56%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1,\n",
       "       0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test data prep for bow model\n",
    "\n",
    "# Separate sequences and labels\n",
    "test_labels = []\n",
    "test_sequences = []\n",
    "\n",
    "# for entry in test_data_:\n",
    "for entry in wasm_test_data_:\n",
    "    label, seq = entry\n",
    "    test_labels.append(label)\n",
    "    test_sequences.append(' '.join(map(str, seq)))\n",
    "\n",
    "# vectorizer = joblib.load('bow_vectorizer.joblib')\n",
    "# Transform test sequences into BoW vectors\n",
    "X_test_bow = vectorizer.transform(test_sequences).toarray()\n",
    "\n",
    "# # Load your trained model\n",
    "# clf_bow = joblib.load('rf_bow_model.joblib')\n",
    "\n",
    "# Make predictions on test data\n",
    "predictions = clf_bow_wasm.predict(X_test_bow)\n",
    "\n",
    "# View predictions\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(test_labels, predictions)\n",
    "precision = precision_score(test_labels, predictions, average='binary')\n",
    "recall = recall_score(test_labels, predictions, average='binary')\n",
    "\n",
    "# print(predictions)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"Precision: {precision * 100:.2f}%\")\n",
    "print(f\"Recall: {recall * 100:.2f}%\")\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "cfd4ebae-f49d-41c9-9cc4-c4a3230d1a32",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "fdc64539-4e07-4301-9eef-63ca15d46ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean confidence of non-fp: 0.4260881796850773\n",
      "Mean confidence of fp: 0.5739118203149227\n"
     ]
    }
   ],
   "source": [
    "preds = []\n",
    "\n",
    "for idx in range(31):\n",
    "    from treeinterpreter import treeinterpreter as ti\n",
    "    i = idx  # or any index\n",
    "    X_single = X_test_bow[i].reshape(1, -1)\n",
    "    prediction, bias, contributions = ti.predict(clf_bow, X_single)\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    # Select class 1 contributions\n",
    "    class_idx = 1\n",
    "    class_contribs = contributions[0][:, class_idx]\n",
    "    \n",
    "    # Sort by absolute value of contributions\n",
    "    top_idx = np.argsort(class_contribs)[::-1]\n",
    "    # top_idx = np.argsort(np.abs(class_contribs))[::-1]\n",
    "    \n",
    "    preds.append(prediction[0])\n",
    "    # print(prediction[0])\n",
    "\n",
    "stacked = np.stack(preds)  # shape will be (6, 2)\n",
    "mean_values = np.mean(stacked, axis=0)\n",
    "\n",
    "print(\"Mean confidence of non-fp:\", mean_values[0])\n",
    "print(\"Mean confidence of fp:\", mean_values[1])\n",
    "\n",
    "# js\n",
    "# Mean confidence of non-fp: 0.2825127649001083\n",
    "# Mean confidence of fp: 0.7174872350998915"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "c6363f4f-89db-4379-b576-d8e341b3c098",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction: [0.5565 0.4435]\n",
      "Bias (base value): [0.87774811 0.12225189]\n",
      "Top contributing features to class 1:\n",
      "MemberExpression:screen: 0.0214\n",
      "MemberExpression:suffixes: 0.0032\n",
      "MemberExpression:getTimezoneOffset: 0.0079\n",
      "CallExpression:webgl: 0.0022\n",
      "MemberExpression:pixelDepth: 0.0007\n",
      "MemberExpression:getChannelData: 0.0008\n",
      "MemberExpression:charging: 0.0021\n",
      "MemberExpression:arrayBuffer: 0.0002\n",
      "MemberExpression:localStorage: 0.0118\n",
      "MemberExpression:getBattery: 0.0016\n",
      "MemberExpression:filename: 0.0008\n",
      "MemberExpression:OfflineAudioContext: 0.0009\n",
      "MemberExpression:Number: 0.0027\n",
      "MemberExpression:referrer: 0.0053\n",
      "MemberExpression:eventStatus: 0.0001\n",
      "ArrayExpression:Marlett: 0.0001\n",
      "Property:hardwareConcurrency: 0.0001\n",
      "ArrayExpression:monospace: 0.0008\n",
      "MemberExpression:visibility: 0.0002\n",
      "SequenceExpression:triangle: 0.0003\n"
     ]
    }
   ],
   "source": [
    "idx = 3\n",
    "from treeinterpreter import treeinterpreter as ti\n",
    "i = idx  # or any index\n",
    "X_single = X_test_bow[i].reshape(1, -1)\n",
    "prediction, bias, contributions = ti.predict(clf_bow, X_single)\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "# Select class 1 contributions\n",
    "class_idx = 1\n",
    "class_contribs = contributions[0][:, class_idx]\n",
    "\n",
    "# Sort by absolute value of contributions\n",
    "top_idx = np.argsort(class_contribs)[::-1]\n",
    "# top_idx = np.argsort(np.abs(class_contribs))[::-1]\n",
    "\n",
    "print(f\"\\nPrediction: {prediction[0]}\")\n",
    "print(f\"Bias (base value): {bias[0]}\")\n",
    "# print(f\"Contributions: {len(contributions[0])}\")\n",
    "print(\"Top contributing features to class 1:\")\n",
    "\n",
    "# for idx in top_idx[:10]:\n",
    "#     print(f\"{feature_names[idx]}: {class_contribs[idx]:.4f}\")\n",
    "\n",
    "pi = []\n",
    "\n",
    "for idx in top_idx[0:20]:\n",
    "    token = feature_names[idx]\n",
    "    if token.isdigit():\n",
    "        token_int = int(token)\n",
    "        readable = index_to_token.get(token_int + 1, f\"[Unknown token {token_int}]\")  # +1 to account for 1-based vocab\n",
    "    else:\n",
    "        readable = token\n",
    "    print(f\"{readable}: {importances[idx]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f14614-58f3-468d-9542-eb899c361dc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe772f6-36d8-40a7-b935-e0b97f51ea8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraped data - 100 random samples- all fp\n",
    "\n",
    "#only js\n",
    "# Accuracy: 78.79%\n",
    "# Precision: 100.00%\n",
    "# Recall: 78.79%\n",
    "\n",
    "#wasm+js\n",
    "# Accuracy: 81.82%\n",
    "# Precision: 100.00%\n",
    "# Recall: 81.82%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4034cc-c493-4f40-99a0-1c85d778d923",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraped data - set 2\n",
    "\n",
    "#only js\n",
    "# Accuracy: 85.19%\n",
    "# Precision: 100.00%\n",
    "# Recall: 85.19%\n",
    "\n",
    "#wasm+js\n",
    "# Accuracy: 88.89%\n",
    "# Precision: 100.00%\n",
    "# Recall: 88.89%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5583caf5-b977-4cfb-94be-7c0c053d4317",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DeepFPD Data\n",
    "\n",
    "# only JS\n",
    "# Accuracy: 81.40%\n",
    "# Precision: 92.31%\n",
    "# Recall: 63.16%\n",
    "\n",
    "#wasm+js\n",
    "# Accuracy: 79.07%\n",
    "# Precision: 91.67%\n",
    "# Recall: 57.89%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "73f88078-7ba0-4d83-ab9c-fac71a802889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test data prep for embedding model\n",
    "# # test_sequences = []\n",
    "# # for seq in test_data:\n",
    "# #     test_sequences.append(seq)\n",
    "\n",
    "# # Load saved embedding_matrix and scaler\n",
    "# embedding_matrix = np.load('embedding_matrix.npy')\n",
    "# scaler = joblib.load('scaler.joblib')\n",
    "\n",
    "# # Compute embeddings for test data\n",
    "# X_test = np.array([average_embedding(test_sequences, embedding_matrix) for seq in test_sequences])\n",
    "\n",
    "# # Standardize using trained scaler\n",
    "# X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "7fa615fe-bd75-4f4f-ab9b-7c670f5fd6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('persistent_data/conversion/combined_converted/js/js_sample_01_20250528_131610.json','r') as f:\n",
    "    js_sample_1 = json.load(f)\n",
    "with open('persistent_data/conversion/combined_converted/wasm/wasm_sample_01_20250528_131610.json','r') as f:\n",
    "    wasm_sample_1 = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "68dfa1cc-50a5-4273-a2f9-759ac7295909",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['457', '461', '463', '465', '467', '469', '472', '474', '477', '478', '487'])\n"
     ]
    }
   ],
   "source": [
    "print(wasm_sample_1[1].keys())\n",
    "# print(wasm_sample_1[1]['461']['content'])\n",
    "# len(wasm_sample_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "c175274e-040b-473a-8447-135f5aa3fcb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('DeepFPD-Code/train/process_token2/script_with_content.json','rb') as f:\n",
    "    deepFPD_train = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "4fed0f09-d822-43e6-8ccb-1136a2006002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': '0',\n",
       " 'content': '(window.webpackJsonp_N_E=window.webpackJsonp_N_E||[]).push([[20],{ZS0p:function(t,n,e){\"use strict\";e.r(n);var r=e(\"q1tI\"),o=e(\"tseg\"),i=e.n(o);n.default=function(t){var n=t.facebookPixelId;return Object(r.useEffect)((function(){n&&(i.a.init(n),i.a.pageView())}),[n]),null}},tseg:function(t,n,e){window,t.exports=function(t){var n={};function e(r){if(n[r])return n[r].exports;var o=n[r]={i:r,l:!1,exports:{}};return t[r].call(o.exports,o,o.exports,e),o.l=!0,o.exports}return e.m=t,e.c=n,e.d=function(t,n,r){e.o(t,n)||Object.defineProperty(t,n,{enumerable:!0,get:r})},e.r=function(t){\"undefined\"!=typeof Symbol&&Symbol.toStringTag&&Object.defineProperty(t,Symbol.toStringTag,{value:\"Module\"}),Object.defineProperty(t,\"__esModule\",{value:!0})},e.t=function(t,n){if(1&n&&(t=e(t)),8&n)return t;if(4&n&&\"object\"==typeof t&&t&&t.__esModule)return t;var r=Object.create(null);if(e.r(r),Object.defineProperty(r,\"default\",{enumerable:!0,value:t}),2&n&&\"string\"!=typeof t)for(var o in t)e.d(r,o,function(n){return t[n]}.bind(null,o));return r},e.n=function(t){var n=t&&t.__esModule?function(){return t.default}:function(){return t};return e.d(n,\"a\",n),n},e.o=function(t,n){return Object.prototype.hasOwnProperty.call(t,n)},e.p=\"\",e(e.s=0)}([function(t,n,e){t.exports=e(1)},function(t,n,e){\"use strict\";function r(t){return function(t){if(Array.isArray(t)){for(var n=0,e=new Array(t.length);n<t.length;n++)e[n]=t[n];return e}}(t)||function(t){if(Symbol.iterator in Object(t)||\"[object Arguments]\"===Object.prototype.toString.call(t))return Array.from(t)}(t)||function(){throw new TypeError(\"Invalid attempt to spread non-iterable instance\")}()}e.r(n);var o=!!window.fbq,i=!1,a=function(){var t;if(i){for(var n=arguments.length,e=new Array(n),o=0;o<n;o++)e[o]=arguments[o];(t=console).info.apply(t,r([\"[react-facebook-pixel]\"].concat(e)))}},c=function(){var t;if(i){for(var n=arguments.length,e=new Array(n),o=0;o<n;o++)e[o]=arguments[o];(t=console).info.apply(t,r([\"[react-facebook-pixel]\"].concat(e)))}},f=function(){return o||a(\"Pixel not initialized before using call ReactPixel.init with required params\"),o},u={autoConfig:!0,debug:!1};n.default={init:function(t){var n,e,r,c,f,l,s=arguments.length>1&&void 0!==arguments[1]?arguments[1]:{},b=arguments.length>2&&void 0!==arguments[2]?arguments[2]:u;n=window,e=document,r=\"script\",n.fbq||(c=n.fbq=function(){c.callMethod?c.callMethod.apply(c,arguments):c.queue.push(arguments)},n._fbq||(n._fbq=c),c.push=c,c.loaded=!0,c.version=\"2.0\",c.queue=[],(f=e.createElement(r)).async=!0,f.src=\"https://connect.facebook.net/en_US/fbevents.js\",(l=e.getElementsByTagName(r)[0]).parentNode.insertBefore(f,l)),t?(!1===b.autoConfig&&fbq(\"set\",\"autoConfig\",!1,t),fbq(\"init\",t,s),o=!0,i=b.debug):a(\"Please insert pixel id for initializing\")},pageView:function(){f()&&(fbq(\"track\",\"PageView\"),i&&c(\"called fbq(\\'track\\', \\'PageView\\');\"))},track:function(t,n){f()&&(fbq(\"track\",t,n),i&&(c(\"called fbq(\\'track\\', \\'\".concat(t,\"\\');\")),n&&c(\"with data\",n)))},trackSingle:function(t,n,e){f()&&(fbq(\"trackSingle\",t,n,e),i&&(c(\"called fbq(\\'trackSingle\\', \\'\".concat(t,\"\\', \\'\").concat(n,\"\\');\")),e&&c(\"with data\",e)))},trackCustom:function(t,n){f()&&(fbq(\"trackCustom\",t,n),i&&(c(\"called fbq(\\'trackCustom\\', \\'\".concat(t,\"\\');\")),n&&c(\"with data\",n)))},trackSingleCustom:function(t,n,e){f()&&(fbq(\"trackSingle\",t,n,e),i&&(c(\"called fbq(\\'trackSingleCustom\\', \\'\".concat(t,\"\\', \\'\").concat(n,\"\\');\")),e&&c(\"with data\",e)))},grantConsent:function(){f()&&(fbq(\"consent\",\"grant\"),i&&c(\"called fbq(\\'consent\\', \\'grant\\');\"))},revokeConsent:function(){f()&&(fbq(\"consent\",\"revoke\"),i&&c(\"called fbq(\\'consent\\', \\'revoke\\');\"))},fbq:function(t){function n(){return t.apply(this,arguments)}return n.toString=function(){return t.toString()},n}((function(){if(f()){for(var t=arguments.length,n=new Array(t),e=0;e<t;e++)n[e]=arguments[e];fbq.apply(void 0,n),i&&(c(\"called fbq(\\'\".concat(n.slice(0,2).join(\"\\', \\'\"),\"\\')\")),n[2]&&c(\"with data\",n[2]))}}))}}])}}]);'}"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list(deepFPD_train.keys())[0]\n",
    "deepFPD_train['002018445aafff40aed85143d61e8f90fc8859cc7df4f2ace93331cdf94b855e']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "eb145549-f47a-4355-9ec0-3e9dcf910f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 209.11it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "count = 0\n",
    "\n",
    "for d in tqdm(wasm_sample_1):\n",
    "    for item in list(d.values()):\n",
    "        count+=1\n",
    "        code = item['content']\n",
    "        with open(f'persistent_data/conversion/scripts_for_fp_inspector/wasm/wasm_{count}.js','w') as f:\n",
    "            f.write(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911df71a-2315-4fb5-bde5-52d3923c7f93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
